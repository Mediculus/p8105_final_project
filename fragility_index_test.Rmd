---
title: "fragility_index_test"
author: "Bryan Bunning"
date: "11/12/2019"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
knitr::opts_chunk$set(echo = TRUE)
```



to grab this data, I did an advanced search on clinicaltrials.gov and downloaded all search results!

```{r}
mydat <- read_csv(file = "SearchResults(1).csv") %>%
  filter(
    str_detect(Interventions, "Placebo")
  )

mydat %>% distinct(Conditions) %>% view()
```

HTML scraping tags

`#EXPAND-outcome-data-1 .labelSubtle` -this is the thing that needs to have participants or "Unit of Measure: Participants"

`#EXPAND-outcome-data-1 td.de-outcomeLabelCell` -this is arm description for primary outcome
`#EXPAND-outcome-data-1 tbody:nth-child(2) th` -this is description of table

```{r}
url_test <- "https://clinicaltrials.gov/ct2/show/results/NCT00195702"

trial_html <- read_html(url_test)

outcome_measure <- 
  trial_html %>%
  html_nodes("#EXPAND-outcome-data-1 .labelSubtle") %>%
  html_text()

#once we do about, grab if statement with 
str_detect(outcome_measure,"[pP]articipants")
str_detect(outcome_measure, "[pP]atients")
#if either of these return true, continue to scraping, else next()

#then we scrap the actual data


#important for col names
#this should always has the first term be "\n    Arm/Group Title \n  " which we will ignore
col_names <- trial_html %>% html_nodes("#EXPAND-outcome-data-1 tbody:nth-child(2) tr:nth-child(1) .de-outcomeLabelCell") %>%
  html_text()
col_names

#important for rownames #ideally this should be participants and unit of measure
row_names <- trial_html %>% html_nodes("#EXPAND-outcome-data-1 .labelSubtle , #EXPAND-outcome-data-1 tbody:nth-child(2) tr:nth-child(4) .de-outcomeLabelCell
") %>%
  html_text()
row_names

#scrape the actual data, with variable table length
test123 <- trial_html %>% html_nodes("#EXPAND-outcome-data-1 .de-numValue_outcomeDataCell") %>%
  html_text()

#get rid of dumb characters
test123 <- test123 %>% as.numeric()

#make into a matrix of correct size 

my_matrix<- matrix(test123, ncol=length(col_names[-1]), nrow=length(row_names), byrow=TRUE)
my_matrix

my_df<- as.tibble(my_matrix)
names(my_df) <- col_names[-1]
#a tibble doesnt show rownames when you call it but it is saved into R
rownames(my_df) <- row_names


#what we should do next is store this into a listcol, and then iterate to the next website!
```


```{r}
###### maybe useful information
has_rownames(my_df)
my_df
rownames(my_df)

my_df
test123
as.data.frame(test123, col.names=(col_names[-1]))
str_remove()

unsure_if_useful<-trial_html %>% html_nodes("#EXPAND-outcome-data-1 td.de-outcomeLabelCell") %>%
  html_text() 
length()

as.data.frame(x, row.names = NULL, optional = FALSE, ...,
              cut.names = FALSE, col.names = names(x), fix.empty.names = TRUE,
              stringsAsFactors = default.stringsAsFactors())

```




```{r test_rclinicaltrials}
library(devtools)
#install_github("sachsmc/rclinicaltrials")
library(rclinicaltrials)
test <- clinicaltrials_download(query = 'asthma', count = 10, include_results = TRUE)

test$study_information$outcomes

myoutcomes<- test$study_information$outcomes
#NCT00182143

test2<- clinicaltrials_download(query = 'NCT01123083', count = 1, include_results = TRUE)

test2$study_results$outcome_data$measure
outcomes<- test2$study_results$outcome_data

test3 <- clinicaltrials_download(query = 'NCT00195702', count = 1, include_results = TRUE)

outcomes2 <- test3$study_results$outcome_data

outcomes3 <- test3$study_results$baseline_data



```







#webscraping from a website

how to do api call over multiple pages so you dont get screwed by api call limits

```{r}
get_all_inspections = function(url) {
  
  all_inspections = vector("list", length = 0)
  
  loop_index = 1
  chunk_size = 50000
  DO_NEXT = TRUE
  
  while (DO_NEXT) {
    message("Getting data, page ", loop_index)
    
    all_inspections[[loop_index]] = 
      GET(url,
          query = list(`$order` = "zipcode",
                       `$limit` = chunk_size,
                       `$offset` = as.integer((loop_index - 1) * chunk_size)
                       )
          ) %>%
      content("text") %>%
      fromJSON() %>%
      as_tibble()
    
    DO_NEXT = dim(all_inspections[[loop_index]])[1] == chunk_size
    loop_index = loop_index + 1
  }
  
  all_inspections
  
}

url = "https://data.cityofnewyork.us/resource/43nn-pn8j.json"

nyc_inspections = get_all_inspections(url) %>%
  bind_rows()
```

another example
```{r}
url <- "https://www.amazon.com/product-reviews/B00005JNBQ/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1"

dynamite_html <- read_html(url)

review_titles <- 
  dynamite_html %>%
  html_nodes(".a-text-bold span") %>%
  html_text()
```

